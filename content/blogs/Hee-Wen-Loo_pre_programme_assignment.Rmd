---
title: "MFA 2022 Pre-Programme Assignment"
date: "7 Sep 2021"
description: This is the 1st R assignment done individually before starting at LBS.
  Assignment includes basic introduction to the basic packages which will be covered
  later in the course.
draft: no
image: h3.jpg
keywords: ''
slug: Hee-Wen-Loo_pre_programme_assignment
categories:
- ''
- ''
---

```{r load-libraries, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(gapminder)  # gapminder dataset
library(here)
library(janitor)
```

# Task 1: Short biography written using markdown

**Hee Wen Loo**

*Nationality:* Singapore 

*Gender*: Female

My name is Hee Wen, and I am currently reading my Masters in Financial Analysis at the London Business School. I was born and raised in Singapore, but moved to London for my undergraduate studies. I have recently completed my Bachelors in Economics from the London School of Economics. 

I have a wide range of hobbies, which include the following: 


- Exploring markets in London


- Watching Korean dramas and Musicals 


- Reading British literature 

I also enjoy trying out new food. Some of the cuisines I enjoy are Korean, Spanish, and Japanese. My favourite restaurant in London is Eat Tokyo. I definitely recommend everyone to try it out! Its website is <https://www.eattokyo.co.uk/>. 

# Task 2: `gapminder` country comparison

```{r}
glimpse(gapminder)

head(gapminder, 20) # look at the first 20 rows of the dataframe

```

I have created the `country_data` and `continent_data` with the code below.

```{r}
country_data <- gapminder %>% 
            filter(country == "China") 

continent_data <- gapminder %>% 
            filter(continent == "Asia")
```


```{r, lifeExp_one_country}
plot1 <- ggplot(data = country_data, mapping = aes(x = year, y = lifeExp))+
geom_point() +
geom_smooth(se = FALSE)+
NULL 

plot1
```

Next we need to add a title. Create a new plot, or extend plot1, using the `labs()` function to add an informative title to the plot.

```{r, lifeExp_one_country_with_label}
plot1<- plot1 +
   labs(title = " Life Expectancy of China ",
       x = " Year",
       y = " Life Expectancy ") +
   NULL


plot1
```

Secondly, produce a plot for all countries in Asia. 

```{r lifeExp_one_continent}
ggplot(continent_data, mapping = aes(x = year , y =  lifeExp, colour= country, group = country)) +
    geom_point() +
   geom_smooth(se = FALSE) +
   NULL
```

Finally, using the original `gapminder` data, produce a life expectancy over time graph, grouped (or faceted) by continent. We will remove all legends, adding the `theme(legend.position="none")` in the end of our ggplot.

```{r lifeExp_facet_by_continent}
ggplot(data = gapminder , mapping = aes(x = year , y =  lifeExp, colour= continent))+
   geom_point() + 
   geom_smooth(se = FALSE) +
   facet_wrap(~continent) +
   theme(legend.position="none") + #remove all legends
   NULL
```

Given these trends, what can you say about life expectancy since 1952? 

> Type your answer after this blockquote.
# Life expectancy has generally been increasing across the different continents since 1952. The life expectancy in Asia has increased the most, as compared to the other continents. This may be attributed to better standards of living, increased access to healthcare and better nutrition in peoples' diets. 
# Life expectancy in Oceania has increased the most gently across the different continents. This may be because the standards of living in Oceania has always been high. As such, we do not observe such a drastic increase in life expectanct since 1952. 

# Task 3: Brexit vote analysis

We will have a look at the results of the 2016 Brexit vote in the UK. First we read the data using `read_csv()` and have a quick glimpse at the data

```{r load_brexit_data, warning=FALSE, message=FALSE}
brexit_results <- read_csv(here::here("data","brexit_results.csv"))


glimpse(brexit_results)
```

The data comes from [Elliott Morris](https://www.thecrosstab.com/), who cleaned it and made it available through his [DataCamp class on analysing election and polling data in R](https://www.datacamp.com/courses/analyzing-election-and-polling-data-in-r).

Our main outcome variable (or y) is `leave_share`, which is the percent of votes cast in favour of Brexit, or leaving the EU. Each row is a UK [parliament constituency](https://en.wikipedia.org/wiki/United_Kingdom_Parliament_constituencies).

To get a sense of the spread, or distribution, of the data, we can plot a histogram, a density plot, and the empirical cumulative distribution function of the leave % in all constituencies.

```{r brexit_histogram, warning=FALSE, message=FALSE}

# histogram
plot2<- ggplot(brexit_results, aes(x = leave_share)) +
  geom_histogram(binwidth = 2.5) +
  labs(title="Brexit Histogram",
       x="Leave Share (%)",
       y="Count")
plot2

# density plot-- think smoothed histogram
plot3<- ggplot(brexit_results, aes(x = leave_share)) +
  geom_density() +
  labs(title="Density Plot",
       x="Leave Share (%)",
       y="Count")
plot3

# The empirical cumulative distribution function (ECDF) 
plot4<-ggplot(brexit_results, aes(x = leave_share)) +
  stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent)+
  labs(title="ECDF",
       x="Leave Share",
       y="%")
plot4


```
One common explanation for the Brexit outcome was fear of immigration and opposition to the EU's more open border policy. We can check the relationship (or correlation) between the proportion of native born residents (`born_in_uk`) in a constituency and its `leave_share`. To do this, let us get the correlation between the two variables

```{r brexit_immigration_correlation}
brexit_results %>% 
  select(leave_share, born_in_uk) %>% 
  cor()
```

The correlation is almost 0.5, which shows that the two variables are positively correlated.

We can also create a scatterplot between these two variables using `geom_point`. We also add the best fit line, using `geom_smooth(method = "lm")`.

```{r brexit_immigration_plot}
ggplot(brexit_results, aes(x = born_in_uk, y = leave_share)) +
  geom_point(alpha=0.3) +
  labs(title="Brexit Immigration Plot",
         x="Born in UK",
       y="Leave Share")+
  
  # add a smoothing line, and use method="lm" to get the best straight-line
  geom_smooth(method = "lm") 
  
  # use a white background and frame the plot with a black box
  theme_bw() +
  NULL
```

> Type your answer after, and outside, this blockquote.
From the diagrams above, there is a strong positive correlation between those born in UK and to vote for Brexit. This may be because of Nationalism, where locals are worried of a dilution in British culture. It may also have been contributed by fears of job loss from foreigners/Europeans.


# Task 4: Animal rescue incidents attended by the London Fire Brigade

[The London Fire Brigade](https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb) attends a range of non-fire incidents (which we call 'special services'). These 'special services' include assistance to animals that may be trapped or in distress. The data is provided from January 2009 and is updated monthly. A range of information is supplied for each incident including some location information (postcode, borough, ward), as well as the data/time of the incidents. We do not routinely record data about animal deaths or injuries.

Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.

```{r load_animal_rescue_data, warning=FALSE, message=FALSE}

url <- "https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/8a7d91c2-9aec-4bde-937a-3998f4717cd8/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv"

animal_rescue <- read_csv(url,
                          locale = locale(encoding = "CP1252")) %>% 
  janitor::clean_names()

glimpse(animal_rescue)
```
One of the more useful things one can do with any data set is quick counts, namely to see how many observations fall within one category. For instance, if we wanted to count the number of incidents by year, we would either use `group_by()... summarise()` or, simply [`count()`](https://dplyr.tidyverse.org/reference/count.html)

```{r, instances_by_calendar_year}

animal_rescue %>% 
  dplyr::group_by(cal_year) %>% 
  summarise(count=n())

animal_rescue %>% 
  count(cal_year, name="count")

```

Let us try to see how many incidents we have by animal group. Again, we can do this either using group_by() and summarise(), or by using count()

```{r, animal_group_percentages}
animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  
  #group_by and summarise will produce a new column with the count in each animal group
  summarise(count = n()) %>% 
  
  # mutate adds a new column; here we calculate the percentage
  mutate(percent = round(100*count/sum(count),2)) %>% 
  
  # arrange() sorts the data by percent. Since the default sorting is min to max and we would like to see it sorted
  # in descending order (max to min), we use arrange(desc()) 
  arrange(desc(percent))


animal_rescue %>% 
  
  #count does the same thing as group_by and summarise
  # name = "count" will call the column with the counts "count" ( exciting, I know)
  # and 'sort=TRUE' will sort them from max to min
  count(animal_group_parent, name="count", sort=TRUE) %>% 
  mutate(percent = round(100*count/sum(count),2))


```

Finally, let us have a look at the notional cost for rescuing each of these animals. As the LFB says,

> Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.

There is two things we will do:

1. Calculate the mean and median `incident_notional_cost` for each `animal_group_parent`
2. Plot a boxplot to get a feel for the distribution of `incident_notional_cost` by `animal_group_parent`.

Now, let us quickly calculate summary statistics for each animal group. 

```{r, stats_on_incident_cost,message=FALSE, warning=FALSE}

animal_rescue %>% 
  
  # group by animal_group_parent
  group_by(animal_group_parent)
  
  # filter resulting data, so each group has at least 6 observations
  filter(animal_rescue, n()>6) %>%
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost, na.rm=TRUE),
            count = n()) %>% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(mean_incident_cost))

```

Finally, let us plot a few plots that show the distribution of incident_cost for each animal group.

```{r, plots_on_incident_cost_by_animal_group,message=FALSE, warning=FALSE}
# base_plot
base_plot <- animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  filter(n()>6) %>% 
  ggplot(aes(x=incident_notional_cost))+
  facet_wrap(~animal_group_parent, scales = "free")+
  theme_bw()

base_plot+geom_density()
base_plot + geom_boxplot()
base_plot + stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent)

```

In my opinion, the box plot is best communicates. It clearly shows the median, range and standard deviations from the median. Ferrets and rabbits are the most expensive to rescue. This may be because they are more active animals, and therefore require more effort/materials to rescue. 

